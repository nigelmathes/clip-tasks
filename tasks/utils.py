# General utilities for CLIP tasks
from pathlib import Path
from typing import Tuple, Callable, Union

import clip
import numpy as np
import PIL
import torch


def get_device() -> str:
    """
    Set PyTorch to run on CPU or GPU based on hardware.

    Returns:
        "cuda" if a GPU is available, otherwise "cpu"
    """
    device = "cuda" if torch.cuda.is_available() else "cpu"

    return device


def get_model_and_preprocess(
    model_name: str = "ViT-B/32",
) -> Tuple[torch.nn.Module, Callable[[PIL.Image.Image], torch.Tensor]]:
    """
    Use clip.load() with an input model string to load the model and preprocessing
    pipeline. Defaults to the "ViT-B/32" model.

    Args:
        model_name: Name of the CLIP model, one of:
                    ["RN50", "RN101", "RN50x4", "ViT-B/32"]

    Returns:
        The loaded model and preprocessing pipeline
    """
    if model_name not in ["RN50", "RN101", "RN50x4", "ViT-B/32"]:
        raise RuntimeError(
            'Model not available. Choose one of: ["RN50", "RN101", "RN50x4", "ViT-B/32"]'
        )

    model, preprocess = clip.load(model_name, device=get_device())

    return model, preprocess


def save_embeddings(
    embeddings: torch.Tensor,
    filename: Union[str, Path],
) -> Union[str, Path]:
    """
    Save text embeddings generated by prompt_engineered_text_embeddings(), defaulting to
    ./outputs/image_embeddings.npy

    Args:
        embeddings: A PyTorch tensor of embedded weights for text/prompt
                         combinations
        filename: Name of file to write

    Returns:
        The name of the file the text embeddings have been saved as
    """
    numpy_embeddings = embeddings.cpu().numpy()
    np.save(filename, numpy_embeddings)

    return filename


def load_embeddings(
    filename: Union[str, Path]
) -> torch.Tensor:
    """
    Load embeddings from a .npy save file

    Args:
        filename: Name of the file containing text embeddings

    Returns:
        Loaded text embeddings as a torch.Tensor
    """
    loaded_embeddings = np.load(filename)
    processed_embeddings = torch.from_numpy(loaded_embeddings).to(get_device())

    return processed_embeddings
